{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"setup","metadata":{}},{"cell_type":"code","source":"# Install required packages\n!apt-get install -y git\n!pip install music21\n!pip install keras\n!pip install tensorflow\n\nimport os\nimport shutil\nimport glob\nimport pickle\nimport numpy\nfrom music21 import converter, instrument, note, chord, stream\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization as BatchNorm\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\nfrom IPython.display import clear_output\n\ndef setup_piano_rnn():\n    \"\"\"Set up the project structure and download MIDI files\"\"\"\n    # Create necessary directories\n    for directory in ['midi_songs', 'data']:\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n            print(f\"Created directory: {directory}\")\n    \n    # Clone the repository\n    !git clone https://github.com/M1shaaa/piano-RNN.git temp_repo\n    \n    # The files are in the midi_songs folder in the repo\n    midi_files = ['1.midi', '2.midi']\n    files_copied = 0\n    \n    print(\"\\nCopying MIDI files...\")\n    for file in midi_files:\n        source = f'temp_repo/midi_songs/{file}'  # Changed path to include midi_songs\n        destination = f'midi_songs/{file}'\n        if os.path.exists(source):\n            shutil.copy2(source, destination)\n            print(f\"Successfully copied {file} to midi_songs directory\")\n            files_copied += 1\n        else:\n            print(f\"Warning: Could not find {file} in the repository\")\n    \n    # Clean up\n    !rm -rf temp_repo\n    \n    # Verify files\n    midi_files = glob.glob('midi_songs/*.midi') + glob.glob('midi_songs/*.mid')\n    print(f\"\\nSetup complete!\")\n    print(f\"Found {len(midi_files)} MIDI files in midi_songs/:\")\n    for file in midi_files:\n        print(f\"- {file}\")\n    \n    if len(midi_files) == 0:\n        raise Exception(\"No MIDI files were copied. Please check the repository structure and file names.\")\n    \n    return len(midi_files) > 0\n\n\n\n# Rest of your code remains the same, but let's add more error checking\ndef get_notes():\n    \"\"\" Get notes and chords from the midi files \"\"\"\n    notes = []\n    midi_files = glob.glob(\"midi_songs/*.midi\") + glob.glob(\"midi_songs/*.mid\")\n    \n    if not midi_files:\n        raise Exception(\"No MIDI files found in midi_songs directory\")\n    \n    for file in midi_files:\n        print(f\"Parsing {file}\")\n        try:\n            midi = converter.parse(file)\n            \n            try:\n                s2 = instrument.partitionByInstrument(midi)\n                notes_to_parse = s2.parts[0].recurse() \n            except:\n                notes_to_parse = midi.flat.notes\n                \n            for element in notes_to_parse:\n                if isinstance(element, note.Note):\n                    notes.append(str(element.pitch))\n                elif isinstance(element, chord.Chord):\n                    notes.append('.'.join(str(n) for n in element.normalOrder))\n                    \n        except Exception as e:\n            print(f\"Error processing {file}: {str(e)}\")\n    \n    if not notes:\n        raise Exception(\"No notes were extracted from the MIDI files\")\n    \n    print(f\"Successfully extracted {len(notes)} notes\")\n    \n    with open('data/notes', 'wb') as filepath:\n        pickle.dump(notes, filepath)\n    \n    return notes\n\ndef prepare_sequences(notes, n_vocab):\n    \"\"\" Prepare sequences for training \"\"\"\n    sequence_length = 100\n    pitchnames = sorted(set(item for item in notes))\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n\n    network_input = []\n    network_output = []\n\n    for i in range(0, len(notes) - sequence_length, 1):\n        sequence_in = notes[i:i + sequence_length]\n        sequence_out = notes[i + sequence_length]\n        network_input.append([note_to_int[char] for char in sequence_in])\n        network_output.append(note_to_int[sequence_out])\n\n    n_patterns = len(network_input)\n    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n    network_input = network_input / float(n_vocab)\n    network_output = to_categorical(network_output)\n\n    return (network_input, network_output)\n\ndef create_network(network_input, n_vocab):\n    \"\"\" Create the neural network \"\"\"\n    model = Sequential()\n    model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), \n                  recurrent_dropout=0.3, return_sequences=True))\n    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3))\n    model.add(LSTM(512))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n    return model\n\n\ndef train_network():\n    \"\"\" Train a Neural Network to generate music \"\"\"\n    notes = get_notes()\n    n_vocab = len(set(notes))\n    network_input, network_output = prepare_sequences(notes, n_vocab)\n    model = create_network(network_input, n_vocab)\n    train(model, network_input, network_output)\n    \n\ndef train(model, network_input, network_output):\n    \"\"\" Train the neural network \"\"\"\n    # Updated filepath to use .keras extension\n    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.keras\"\n    \n    checkpoint = ModelCheckpoint(\n        filepath,\n        monitor='loss',\n        verbose=1,  # Changed to 1 to see more progress info\n        save_best_only=True,\n        mode='min'\n    )\n    callbacks_list = [checkpoint]\n    \n    model.fit(\n        network_input, \n        network_output, \n        epochs=200, \n        batch_size=128, \n        callbacks=callbacks_list,\n        verbose=1  # Added verbose=1 for more detailed progress\n    )\n\n\n\n# Start training with error handling\nif __name__ == '__main__':\n    try:\n        if setup_piano_rnn():\n            print(\"\\nStarting training process...\")\n            train_network()\n        else:\n            print(\"Setup failed. Please check the errors above.\")\n    except Exception as e:\n        print(f\"Error during execution: {str(e)}\")","metadata":{"trusted":true,"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import statements remain the same...\nimport os\nimport glob\nimport pickle\nimport numpy\nfrom music21 import converter, instrument, note, chord, stream\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization as BatchNorm\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\n\ndef resume_training():\n    \"\"\"Resume training from the last checkpoint\"\"\"\n    # Load the notes\n    with open('data/notes', 'rb') as filepath:\n        notes = pickle.load(filepath)\n    \n    # Get preparation values\n    n_vocab = len(set(notes))\n    network_input, network_output = prepare_sequences(notes, n_vocab)\n    \n    # Find the most recent checkpoint\n    checkpoint_files = glob.glob(\"weights-improvement-*-*.keras\")\n    if not checkpoint_files:\n        print(\"No checkpoint found. Starting fresh training...\")\n        model = create_network(network_input, n_vocab)\n        initial_epoch = 0\n    else:\n        latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n        print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n        # Get the epoch number from the filename\n        epoch_str = latest_checkpoint.split('-')[2]\n        initial_epoch = int(epoch_str)\n        # Load the model with weights\n        model = create_network(network_input, n_vocab)\n        model.load_weights(latest_checkpoint)\n    \n    # Continue training\n    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.keras\"\n    checkpoint = ModelCheckpoint(\n        filepath,\n        monitor='loss',\n        verbose=1,\n        save_best_only=True,\n        mode='min'\n    )\n    callbacks_list = [checkpoint]\n    \n    model.fit(\n        network_input, \n        network_output, \n        epochs=200,\n        initial_epoch=initial_epoch,  # Start from the last epoch\n        batch_size=128, \n        callbacks=callbacks_list,\n        verbose=1\n    )\n\n# The rest of your functions (prepare_sequences, create_network, etc.) remain the same...\n\nif __name__ == '__main__':\n    try:\n        print(\"\\nResuming training process...\")\n        resume_training()\n    except Exception as e:\n        print(f\"Error during execution: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T17:51:34.114425Z","iopub.execute_input":"2024-12-01T17:51:34.114796Z","iopub.status.idle":"2024-12-01T17:51:34.346671Z","shell.execute_reply.started":"2024-12-01T17:51:34.114763Z","shell.execute_reply":"2024-12-01T17:51:34.345215Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusic21\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m converter, instrument, note, chord, stream\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, load_model\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, LSTM, Activation, BatchNormalization \u001b[38;5;28;01mas\u001b[39;00m BatchNorm\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'music21'"],"ename":"ModuleNotFoundError","evalue":"No module named 'music21'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"import pickle\nimport numpy\nfrom music21 import instrument, note, stream, chord\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization as BatchNorm\nfrom keras.utils import to_categorical\n\ndef generate():\n    \"\"\" Generate a piano midi file \"\"\"\n    #load the notes used to train the model\n    with open('data/notes', 'rb') as filepath:\n        notes = pickle.load(filepath)\n\n    # Get all pitch names\n    pitchnames = sorted(set(item for item in notes))\n    n_vocab = len(set(notes))\n\n    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n    model = create_network(normalized_input, n_vocab)\n    \n    # Use the most recent weights file\n    model.load_weights('weights-improvement-200-2.8755-bigger.keras')\n    \n    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n    create_midi(prediction_output)\n\ndef prepare_sequences(notes, pitchnames, n_vocab):\n    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n\n    sequence_length = 100\n    network_input = []\n    for i in range(0, len(notes) - sequence_length, 1):\n        sequence_in = notes[i:i + sequence_length]\n        network_input.append([note_to_int[char] for char in sequence_in])\n\n    n_patterns = len(network_input)\n    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n    normalized_input = normalized_input / float(n_vocab)\n\n    return (network_input, normalized_input)\n\ndef create_network(network_input, n_vocab):\n    \"\"\" create the structure of the neural network \"\"\"\n    model = Sequential()\n    model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n    model.add(Dropout(0.3))\n    model.add(LSTM(512, return_sequences=True))\n    model.add(Dropout(0.3))\n    model.add(LSTM(512))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n    return model\n\ndef generate_notes(model, network_input, pitchnames, n_vocab):\n    \"\"\" Generate notes from the neural network \"\"\"\n    # Pick a random sequence from the input as a starting point\n    start = numpy.random.randint(0, len(network_input)-1)\n    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n\n    pattern = network_input[start]\n    prediction_output = []\n\n    # Generate 500 notes\n    for note_index in range(500):\n        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n        prediction_input = prediction_input / float(n_vocab)\n\n        prediction = model.predict(prediction_input, verbose=0)\n        index = numpy.argmax(prediction)\n        result = int_to_note[index]\n        prediction_output.append(result)\n        \n        pattern.append(index)\n        pattern = pattern[1:len(pattern)]\n\n    return prediction_output\n\ndef create_midi(prediction_output):\n    \"\"\" convert the output from the prediction to notes and create a midi file \"\"\"\n    offset = 0\n    output_notes = []\n\n    # Create note and chord objects\n    for pattern in prediction_output:\n        # Pattern is a chord\n        if ('.' in pattern) or pattern.isdigit():\n            notes_in_chord = pattern.split('.')\n            notes = []\n            for current_note in notes_in_chord:\n                new_note = note.Note(int(current_note))\n                new_note.storedInstrument = instrument.Piano()\n                notes.append(new_note)\n            new_chord = chord.Chord(notes)\n            new_chord.offset = offset\n            output_notes.append(new_chord)\n        # Pattern is a note\n        else:\n            new_note = note.Note(pattern)\n            new_note.offset = offset\n            new_note.storedInstrument = instrument.Piano()\n            output_notes.append(new_note)\n\n        offset += 0.5\n\n    midi_stream = stream.Stream(output_notes)\n    midi_stream.write('midi', fp='output_1.mid')\n\nif __name__ == '__main__':\n    generate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T03:34:10.287385Z","iopub.execute_input":"2024-12-01T03:34:10.287738Z","iopub.status.idle":"2024-12-01T03:34:42.963805Z","shell.execute_reply.started":"2024-12-01T03:34:10.287708Z","shell.execute_reply":"2024-12-01T03:34:42.963062Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":9}]}