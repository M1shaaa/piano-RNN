{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"setup","metadata":{}},{"cell_type":"code","source":"# Install required packages\n!apt-get install -y git\n!pip install music21\n!pip install keras\n!pip install tensorflow\n\nimport os\nimport shutil\nimport glob\nimport pickle\nimport numpy\nfrom music21 import converter, instrument, note, chord, stream\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization as BatchNorm\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\n\ndef setup_piano_rnn():\n    \"\"\"Set up the project structure and download MIDI files\"\"\"\n    # Create necessary directories\n    for directory in ['midi_songs', 'data']:\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n            print(f\"Created directory: {directory}\")\n    \n    # Clone the repository\n    !git clone https://github.com/M1shaaa/piano-RNN.git temp_repo\n    \n    # The files are in the midi_songs folder in the repo\n    midi_files = ['1.midi', '2.midi']\n    files_copied = 0\n    \n    print(\"\\nCopying MIDI files...\")\n    for file in midi_files:\n        source = f'temp_repo/midi_songs/{file}'  # Changed path to include midi_songs\n        destination = f'midi_songs/{file}'\n        if os.path.exists(source):\n            shutil.copy2(source, destination)\n            print(f\"Successfully copied {file} to midi_songs directory\")\n            files_copied += 1\n        else:\n            print(f\"Warning: Could not find {file} in the repository\")\n    \n    # Clean up\n    !rm -rf temp_repo\n    \n    # Verify files\n    midi_files = glob.glob('midi_songs/*.midi') + glob.glob('midi_songs/*.mid')\n    print(f\"\\nSetup complete!\")\n    print(f\"Found {len(midi_files)} MIDI files in midi_songs/:\")\n    for file in midi_files:\n        print(f\"- {file}\")\n    \n    if len(midi_files) == 0:\n        raise Exception(\"No MIDI files were copied. Please check the repository structure and file names.\")\n    \n    return len(midi_files) > 0\n\n\n\n# Rest of your code remains the same, but let's add more error checking\ndef get_notes():\n    \"\"\" Get notes and chords from the midi files \"\"\"\n    notes = []\n    midi_files = glob.glob(\"midi_songs/*.midi\") + glob.glob(\"midi_songs/*.mid\")\n    \n    if not midi_files:\n        raise Exception(\"No MIDI files found in midi_songs directory\")\n    \n    for file in midi_files:\n        print(f\"Parsing {file}\")\n        try:\n            midi = converter.parse(file)\n            \n            try:\n                s2 = instrument.partitionByInstrument(midi)\n                notes_to_parse = s2.parts[0].recurse() \n            except:\n                notes_to_parse = midi.flat.notes\n                \n            for element in notes_to_parse:\n                if isinstance(element, note.Note):\n                    notes.append(str(element.pitch))\n                elif isinstance(element, chord.Chord):\n                    notes.append('.'.join(str(n) for n in element.normalOrder))\n                    \n        except Exception as e:\n            print(f\"Error processing {file}: {str(e)}\")\n    \n    if not notes:\n        raise Exception(\"No notes were extracted from the MIDI files\")\n    \n    print(f\"Successfully extracted {len(notes)} notes\")\n    \n    with open('data/notes', 'wb') as filepath:\n        pickle.dump(notes, filepath)\n    \n    return notes\n\ndef prepare_sequences(notes, n_vocab):\n    \"\"\" Prepare sequences for training \"\"\"\n    sequence_length = 100\n    pitchnames = sorted(set(item for item in notes))\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n\n    network_input = []\n    network_output = []\n\n    for i in range(0, len(notes) - sequence_length, 1):\n        sequence_in = notes[i:i + sequence_length]\n        sequence_out = notes[i + sequence_length]\n        network_input.append([note_to_int[char] for char in sequence_in])\n        network_output.append(note_to_int[sequence_out])\n\n    n_patterns = len(network_input)\n    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n    network_input = network_input / float(n_vocab)\n    network_output = to_categorical(network_output)\n\n    return (network_input, network_output)\n\ndef create_network(network_input, n_vocab):\n    \"\"\" Create the neural network \"\"\"\n    model = Sequential()\n    model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), \n                  recurrent_dropout=0.3, return_sequences=True))\n    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3))\n    model.add(LSTM(512))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n    return model\n\n\ndef train_network():\n    \"\"\" Train a Neural Network to generate music \"\"\"\n    notes = get_notes()\n    n_vocab = len(set(notes))\n    network_input, network_output = prepare_sequences(notes, n_vocab)\n    model = create_network(network_input, n_vocab)\n    train(model, network_input, network_output)\n    \n\ndef train(model, network_input, network_output):\n    \"\"\" Train the neural network \"\"\"\n    # Updated filepath to use .keras extension\n    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.keras\"\n    \n    checkpoint = ModelCheckpoint(\n        filepath,\n        monitor='loss',\n        verbose=1,  # Changed to 1 to see more progress info\n        save_best_only=True,\n        mode='min'\n    )\n    callbacks_list = [checkpoint]\n    \n    model.fit(\n        network_input, \n        network_output, \n        epochs=200, \n        batch_size=128, \n        callbacks=callbacks_list,\n        verbose=1  # Added verbose=1 for more detailed progress\n    )\n\n\n\n# Start training with error handling\nif __name__ == '__main__':\n    try:\n        if setup_piano_rnn():\n            print(\"\\nStarting training process...\")\n            train_network()\n        else:\n            print(\"Setup failed. Please check the errors above.\")\n    except Exception as e:\n        print(f\"Error during execution: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T00:34:13.658157Z","iopub.execute_input":"2024-12-01T00:34:13.658526Z","iopub.status.idle":"2024-12-01T01:39:21.184402Z","shell.execute_reply.started":"2024-12-01T00:34:13.658495Z","shell.execute_reply":"2024-12-01T01:39:21.182959Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ngit is already the newest version (1:2.34.1-1ubuntu1.11).\n0 upgraded, 0 newly installed, 0 to remove and 68 not upgraded.\nRequirement already satisfied: music21 in /opt/conda/lib/python3.10/site-packages (9.3.0)\nRequirement already satisfied: chardet in /opt/conda/lib/python3.10/site-packages (from music21) (5.2.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from music21) (1.4.2)\nRequirement already satisfied: jsonpickle in /opt/conda/lib/python3.10/site-packages (from music21) (4.0.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from music21) (3.7.5)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from music21) (10.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from music21) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from music21) (2.32.3)\nRequirement already satisfied: webcolors>=1.5 in /opt/conda/lib/python3.10/site-packages (from music21) (24.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->music21) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->music21) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->music21) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->music21) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->music21) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->music21) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->music21) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->music21) (2.9.0.post0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->music21) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->music21) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->music21) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->music21) (2024.8.30)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.16.0)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.11.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.3.2)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.12.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nCloning into 'temp_repo'...\nremote: Enumerating objects: 177, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (6/6), done.\u001b[K\nremote: Total 177 (delta 1), reused 6 (delta 1), pack-reused 170 (from 1)\u001b[K\nReceiving objects: 100% (177/177), 157.00 MiB | 43.83 MiB/s, done.\nResolving deltas: 100% (27/27), done.\n\nCopying MIDI files...\nSuccessfully copied 1.midi to midi_songs directory\nSuccessfully copied 2.midi to midi_songs directory\n\nSetup complete!\nFound 2 MIDI files in midi_songs/:\n- midi_songs/2.midi\n- midi_songs/1.midi\n\nStarting training process...\nParsing midi_songs/2.midi\nParsing midi_songs/1.midi\nSuccessfully extracted 23609 notes\nEpoch 1/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 7.0761\nEpoch 1: loss improved from inf to 6.82920, saving model to weights-improvement-01-6.8292-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 233ms/step - loss: 7.0747\nEpoch 2/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 5.8579\nEpoch 2: loss improved from 6.82920 to 5.69488, saving model to weights-improvement-02-5.6949-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 233ms/step - loss: 5.8570\nEpoch 3/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 5.4996\nEpoch 3: loss improved from 5.69488 to 5.48228, saving model to weights-improvement-03-5.4823-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 236ms/step - loss: 5.4995\nEpoch 4/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.4520\nEpoch 4: loss improved from 5.48228 to 5.44325, saving model to weights-improvement-04-5.4432-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.4519\nEpoch 5/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.4220\nEpoch 5: loss improved from 5.44325 to 5.40988, saving model to weights-improvement-05-5.4099-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.4219\nEpoch 6/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 5.3639\nEpoch 6: loss improved from 5.40988 to 5.37372, saving model to weights-improvement-06-5.3737-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 233ms/step - loss: 5.3640\nEpoch 7/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 5.3454\nEpoch 7: loss improved from 5.37372 to 5.34471, saving model to weights-improvement-07-5.3447-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 233ms/step - loss: 5.3454\nEpoch 8/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.3333\nEpoch 8: loss improved from 5.34471 to 5.32534, saving model to weights-improvement-08-5.3253-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.3332\nEpoch 9/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 5.3000\nEpoch 9: loss improved from 5.32534 to 5.30907, saving model to weights-improvement-09-5.3091-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 233ms/step - loss: 5.3001\nEpoch 10/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.2898\nEpoch 10: loss improved from 5.30907 to 5.29581, saving model to weights-improvement-10-5.2958-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.2898\nEpoch 11/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.2671\nEpoch 11: loss improved from 5.29581 to 5.28725, saving model to weights-improvement-11-5.2872-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.2672\nEpoch 12/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.2790\nEpoch 12: loss improved from 5.28725 to 5.27772, saving model to weights-improvement-12-5.2777-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.2790\nEpoch 13/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.2538\nEpoch 13: loss improved from 5.27772 to 5.27073, saving model to weights-improvement-13-5.2707-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.2539\nEpoch 14/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.2562\nEpoch 14: loss improved from 5.27073 to 5.26305, saving model to weights-improvement-14-5.2631-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.2563\nEpoch 15/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.2409\nEpoch 15: loss improved from 5.26305 to 5.25767, saving model to weights-improvement-15-5.2577-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.2410\nEpoch 16/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.2442\nEpoch 16: loss improved from 5.25767 to 5.25527, saving model to weights-improvement-16-5.2553-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.2442\nEpoch 17/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 5.2475\nEpoch 17: loss improved from 5.25527 to 5.25035, saving model to weights-improvement-17-5.2503-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 233ms/step - loss: 5.2475\nEpoch 18/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.2402\nEpoch 18: loss improved from 5.25035 to 5.24660, saving model to weights-improvement-18-5.2466-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.2402\nEpoch 19/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.2377\nEpoch 19: loss improved from 5.24660 to 5.24414, saving model to weights-improvement-19-5.2441-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.2377\nEpoch 20/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.2270\nEpoch 20: loss did not improve from 5.24414\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.2271\nEpoch 21/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.2336\nEpoch 21: loss improved from 5.24414 to 5.23705, saving model to weights-improvement-21-5.2371-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.2336\nEpoch 22/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.2213\nEpoch 22: loss improved from 5.23705 to 5.23262, saving model to weights-improvement-22-5.2326-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.2214\nEpoch 23/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.2173\nEpoch 23: loss improved from 5.23262 to 5.22688, saving model to weights-improvement-23-5.2269-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.2173\nEpoch 24/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.2105\nEpoch 24: loss improved from 5.22688 to 5.22301, saving model to weights-improvement-24-5.2230-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.2106\nEpoch 25/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.2339\nEpoch 25: loss improved from 5.22301 to 5.22157, saving model to weights-improvement-25-5.2216-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.2338\nEpoch 26/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.2165\nEpoch 26: loss did not improve from 5.22157\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.2166\nEpoch 27/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.4103\nEpoch 27: loss did not improve from 5.22157\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.4101\nEpoch 28/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.2615\nEpoch 28: loss did not improve from 5.22157\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.2616\nEpoch 29/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.3115\nEpoch 29: loss did not improve from 5.22157\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 5.3114\nEpoch 30/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 5.2834\nEpoch 30: loss did not improve from 5.22157\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.2834\nEpoch 31/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 5.2512\nEpoch 31: loss did not improve from 5.22157\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 234ms/step - loss: 5.2513\nEpoch 32/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 5.2161\nEpoch 32: loss did not improve from 5.22157\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 236ms/step - loss: 5.2161\nEpoch 33/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 5.2270\nEpoch 33: loss improved from 5.22157 to 5.22022, saving model to weights-improvement-33-5.2202-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 234ms/step - loss: 5.2270\nEpoch 34/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 5.2047\nEpoch 34: loss improved from 5.22022 to 5.20576, saving model to weights-improvement-34-5.2058-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 234ms/step - loss: 5.2047\nEpoch 35/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 5.1916\nEpoch 35: loss improved from 5.20576 to 5.20565, saving model to weights-improvement-35-5.2057-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 233ms/step - loss: 5.1917\nEpoch 36/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.1892\nEpoch 36: loss improved from 5.20565 to 5.20295, saving model to weights-improvement-36-5.2029-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.1893\nEpoch 37/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.1853\nEpoch 37: loss improved from 5.20295 to 5.19940, saving model to weights-improvement-37-5.1994-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.1854\nEpoch 38/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.1688\nEpoch 38: loss improved from 5.19940 to 5.19570, saving model to weights-improvement-38-5.1957-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.1689\nEpoch 39/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.1827\nEpoch 39: loss improved from 5.19570 to 5.19075, saving model to weights-improvement-39-5.1908-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.1827\nEpoch 40/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.1968\nEpoch 40: loss improved from 5.19075 to 5.19025, saving model to weights-improvement-40-5.1902-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.1968\nEpoch 41/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.1623\nEpoch 41: loss improved from 5.19025 to 5.18383, saving model to weights-improvement-41-5.1838-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.1624\nEpoch 42/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.1787\nEpoch 42: loss improved from 5.18383 to 5.18142, saving model to weights-improvement-42-5.1814-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.1787\nEpoch 43/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.1548\nEpoch 43: loss improved from 5.18142 to 5.17480, saving model to weights-improvement-43-5.1748-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.1549\nEpoch 44/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 5.1559\nEpoch 44: loss improved from 5.17480 to 5.17403, saving model to weights-improvement-44-5.1740-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 5.1560\nEpoch 45/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.1549\nEpoch 45: loss improved from 5.17403 to 5.17140, saving model to weights-improvement-45-5.1714-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.1550\nEpoch 46/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.1644\nEpoch 46: loss improved from 5.17140 to 5.16329, saving model to weights-improvement-46-5.1633-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.1644\nEpoch 47/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 5.1702\nEpoch 47: loss improved from 5.16329 to 5.16253, saving model to weights-improvement-47-5.1625-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 234ms/step - loss: 5.1702\nEpoch 48/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.1460\nEpoch 48: loss improved from 5.16253 to 5.15876, saving model to weights-improvement-48-5.1588-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.1461\nEpoch 49/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.1427\nEpoch 49: loss improved from 5.15876 to 5.15678, saving model to weights-improvement-49-5.1568-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.1428\nEpoch 50/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.1475\nEpoch 50: loss improved from 5.15678 to 5.15219, saving model to weights-improvement-50-5.1522-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.1475\nEpoch 51/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 5.1315\nEpoch 51: loss improved from 5.15219 to 5.14680, saving model to weights-improvement-51-5.1468-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 5.1315\nEpoch 52/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 5.1387\nEpoch 52: loss improved from 5.14680 to 5.14280, saving model to weights-improvement-52-5.1428-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 5.1388\nEpoch 53/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.1359\nEpoch 53: loss improved from 5.14280 to 5.14193, saving model to weights-improvement-53-5.1419-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.1359\nEpoch 54/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.1398\nEpoch 54: loss improved from 5.14193 to 5.13803, saving model to weights-improvement-54-5.1380-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.1397\nEpoch 55/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 5.1215\nEpoch 55: loss improved from 5.13803 to 5.13536, saving model to weights-improvement-55-5.1354-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 5.1216\nEpoch 56/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 5.1879\nEpoch 56: loss did not improve from 5.13536\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 5.1879\nEpoch 57/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.1583\nEpoch 57: loss did not improve from 5.13536\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 5.1583\nEpoch 58/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 5.1330\nEpoch 58: loss did not improve from 5.13536\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 5.1330\nEpoch 59/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 5.1111\nEpoch 59: loss did not improve from 5.13536\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 5.1113\nEpoch 60/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.1260\nEpoch 60: loss improved from 5.13536 to 5.13022, saving model to weights-improvement-60-5.1302-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.1260\nEpoch 61/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.1098\nEpoch 61: loss improved from 5.13022 to 5.12232, saving model to weights-improvement-61-5.1223-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.1099\nEpoch 62/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.1063\nEpoch 62: loss improved from 5.12232 to 5.11689, saving model to weights-improvement-62-5.1169-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.1064\nEpoch 63/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.0995\nEpoch 63: loss improved from 5.11689 to 5.11336, saving model to weights-improvement-63-5.1134-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.0995\nEpoch 64/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0863\nEpoch 64: loss improved from 5.11336 to 5.11011, saving model to weights-improvement-64-5.1101-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.0864\nEpoch 65/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0878\nEpoch 65: loss improved from 5.11011 to 5.10729, saving model to weights-improvement-65-5.1073-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.0879\nEpoch 66/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 5.0838\nEpoch 66: loss improved from 5.10729 to 5.10329, saving model to weights-improvement-66-5.1033-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 234ms/step - loss: 5.0839\nEpoch 67/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 5.0701\nEpoch 67: loss improved from 5.10329 to 5.09924, saving model to weights-improvement-67-5.0992-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 5.0703\nEpoch 68/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0816\nEpoch 68: loss improved from 5.09924 to 5.09565, saving model to weights-improvement-68-5.0956-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 5.0816\nEpoch 69/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.0888\nEpoch 69: loss improved from 5.09565 to 5.09184, saving model to weights-improvement-69-5.0918-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.0888\nEpoch 70/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0519\nEpoch 70: loss improved from 5.09184 to 5.08821, saving model to weights-improvement-70-5.0882-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.0521\nEpoch 71/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0618\nEpoch 71: loss improved from 5.08821 to 5.08555, saving model to weights-improvement-71-5.0856-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.0619\nEpoch 72/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 5.0585\nEpoch 72: loss improved from 5.08555 to 5.07695, saving model to weights-improvement-72-5.0769-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 235ms/step - loss: 5.0586\nEpoch 73/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.0758\nEpoch 73: loss did not improve from 5.07695\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.0758\nEpoch 74/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 5.0528\nEpoch 74: loss improved from 5.07695 to 5.06908, saving model to weights-improvement-74-5.0691-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 5.0529\nEpoch 75/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0429\nEpoch 75: loss improved from 5.06908 to 5.06627, saving model to weights-improvement-75-5.0663-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.0430\nEpoch 76/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0667\nEpoch 76: loss did not improve from 5.06627\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 5.0667\nEpoch 77/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.0591\nEpoch 77: loss improved from 5.06627 to 5.05977, saving model to weights-improvement-77-5.0598-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 5.0591\nEpoch 78/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 5.0335\nEpoch 78: loss improved from 5.05977 to 5.05632, saving model to weights-improvement-78-5.0563-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 233ms/step - loss: 5.0337\nEpoch 79/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 5.0039\nEpoch 82: loss improved from 5.04206 to 5.04061, saving model to weights-improvement-82-5.0406-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 5.0041\nEpoch 83/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0142\nEpoch 83: loss improved from 5.04061 to 5.03593, saving model to weights-improvement-83-5.0359-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.0143\nEpoch 84/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 5.0171\nEpoch 84: loss improved from 5.03593 to 5.03068, saving model to weights-improvement-84-5.0307-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 5.0172\nEpoch 85/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0064\nEpoch 85: loss improved from 5.03068 to 5.02383, saving model to weights-improvement-85-5.0238-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 5.0065\nEpoch 86/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0186\nEpoch 86: loss improved from 5.02383 to 5.02303, saving model to weights-improvement-86-5.0230-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.0186\nEpoch 87/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 5.0137\nEpoch 87: loss improved from 5.02303 to 5.01730, saving model to weights-improvement-87-5.0173-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 5.0137\nEpoch 88/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.9977\nEpoch 88: loss improved from 5.01730 to 5.01053, saving model to weights-improvement-88-5.0105-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.9977\nEpoch 89/200\n\u001b[1m 48/184\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 228ms/step - loss: 4.9825","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 180\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_piano_rnn():\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training process...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 180\u001b[0m     \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetup failed. Please check the errors above.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[5], line 147\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m network_input, network_output \u001b[38;5;241m=\u001b[39m prepare_sequences(notes, n_vocab)\n\u001b[1;32m    146\u001b[0m model \u001b[38;5;241m=\u001b[39m create_network(network_input, n_vocab)\n\u001b[0;32m--> 147\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork_output\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[5], line 164\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, network_input, network_output)\u001b[0m\n\u001b[1;32m    155\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\n\u001b[1;32m    156\u001b[0m     filepath,\n\u001b[1;32m    157\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    162\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [checkpoint]\n\u001b[0;32m--> 164\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Added verbose=1 for more detailed progress\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"# Import statements remain the same...\nimport os\nimport glob\nimport pickle\nimport numpy\nfrom music21 import converter, instrument, note, chord, stream\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization as BatchNorm\nfrom keras.utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint\n\ndef resume_training():\n    \"\"\"Resume training from the last checkpoint\"\"\"\n    # Load the notes\n    with open('data/notes', 'rb') as filepath:\n        notes = pickle.load(filepath)\n    \n    # Get preparation values\n    n_vocab = len(set(notes))\n    network_input, network_output = prepare_sequences(notes, n_vocab)\n    \n    # Find the most recent checkpoint\n    checkpoint_files = glob.glob(\"weights-improvement-*-*.keras\")\n    if not checkpoint_files:\n        print(\"No checkpoint found. Starting fresh training...\")\n        model = create_network(network_input, n_vocab)\n        initial_epoch = 0\n    else:\n        latest_checkpoint = max(checkpoint_files, key=os.path.getctime)\n        print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n        # Get the epoch number from the filename\n        epoch_str = latest_checkpoint.split('-')[2]\n        initial_epoch = int(epoch_str)\n        # Load the model with weights\n        model = create_network(network_input, n_vocab)\n        model.load_weights(latest_checkpoint)\n    \n    # Continue training\n    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.keras\"\n    checkpoint = ModelCheckpoint(\n        filepath,\n        monitor='loss',\n        verbose=1,\n        save_best_only=True,\n        mode='min'\n    )\n    callbacks_list = [checkpoint]\n    \n    model.fit(\n        network_input, \n        network_output, \n        epochs=200,\n        initial_epoch=initial_epoch,  # Start from the last epoch\n        batch_size=128, \n        callbacks=callbacks_list,\n        verbose=1\n    )\n\n# The rest of your functions (prepare_sequences, create_network, etc.) remain the same...\n\nif __name__ == '__main__':\n    try:\n        print(\"\\nResuming training process...\")\n        resume_training()\n    except Exception as e:\n        print(f\"Error during execution: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T01:39:41.411907Z","iopub.execute_input":"2024-12-01T01:39:41.412870Z","iopub.status.idle":"2024-12-01T02:58:49.721904Z","shell.execute_reply.started":"2024-12-01T01:39:41.412829Z","shell.execute_reply":"2024-12-01T02:58:49.721152Z"}},"outputs":[{"name":"stdout","text":"\nResuming training process...\nResuming from checkpoint: weights-improvement-88-5.0105-bigger.keras\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 19 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 4.9808\nEpoch 89: loss improved from inf to 5.01547, saving model to weights-improvement-89-5.0155-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 225ms/step - loss: 4.9810\nEpoch 90/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.9911\nEpoch 90: loss improved from 5.01547 to 5.00364, saving model to weights-improvement-90-5.0036-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.9911\nEpoch 91/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 4.9838\nEpoch 91: loss improved from 5.00364 to 4.99927, saving model to weights-improvement-91-4.9993-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 225ms/step - loss: 4.9839\nEpoch 92/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 4.9791\nEpoch 92: loss improved from 4.99927 to 4.99269, saving model to weights-improvement-92-4.9927-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 226ms/step - loss: 4.9792\nEpoch 93/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 4.9651\nEpoch 93: loss improved from 4.99269 to 4.98475, saving model to weights-improvement-93-4.9847-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 226ms/step - loss: 4.9652\nEpoch 94/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 4.9583\nEpoch 94: loss improved from 4.98475 to 4.98314, saving model to weights-improvement-94-4.9831-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 224ms/step - loss: 4.9585\nEpoch 95/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 4.9574\nEpoch 95: loss improved from 4.98314 to 4.97630, saving model to weights-improvement-95-4.9763-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 224ms/step - loss: 4.9575\nEpoch 96/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 4.9401\nEpoch 96: loss improved from 4.97630 to 4.96823, saving model to weights-improvement-96-4.9682-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 225ms/step - loss: 4.9403\nEpoch 97/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.9311\nEpoch 97: loss improved from 4.96823 to 4.96458, saving model to weights-improvement-97-4.9646-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.9312\nEpoch 98/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 4.9443\nEpoch 98: loss improved from 4.96458 to 4.95813, saving model to weights-improvement-98-4.9581-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 225ms/step - loss: 4.9444\nEpoch 99/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 4.9262\nEpoch 99: loss improved from 4.95813 to 4.95057, saving model to weights-improvement-99-4.9506-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 224ms/step - loss: 4.9263\nEpoch 100/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - loss: 4.9222\nEpoch 100: loss improved from 4.95057 to 4.93912, saving model to weights-improvement-100-4.9391-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 225ms/step - loss: 4.9223\nEpoch 101/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - loss: 4.9015\nEpoch 101: loss did not improve from 4.93912\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 222ms/step - loss: 4.9017\nEpoch 102/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - loss: 4.9078\nEpoch 102: loss improved from 4.93912 to 4.93492, saving model to weights-improvement-102-4.9349-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 224ms/step - loss: 4.9079\nEpoch 103/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 4.9050\nEpoch 103: loss improved from 4.93492 to 4.92700, saving model to weights-improvement-103-4.9270-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 225ms/step - loss: 4.9051\nEpoch 104/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.8872\nEpoch 104: loss improved from 4.92700 to 4.91669, saving model to weights-improvement-104-4.9167-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.8874\nEpoch 105/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.8714\nEpoch 105: loss improved from 4.91669 to 4.91314, saving model to weights-improvement-105-4.9131-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.8717\nEpoch 106/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 4.8907\nEpoch 106: loss improved from 4.91314 to 4.90240, saving model to weights-improvement-106-4.9024-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 226ms/step - loss: 4.8907\nEpoch 107/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.8837\nEpoch 107: loss did not improve from 4.90240\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 226ms/step - loss: 4.8838\nEpoch 108/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 4.8718\nEpoch 108: loss improved from 4.90240 to 4.89572, saving model to weights-improvement-108-4.8957-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 226ms/step - loss: 4.8720\nEpoch 109/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 4.8557\nEpoch 109: loss improved from 4.89572 to 4.89431, saving model to weights-improvement-109-4.8943-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 226ms/step - loss: 4.8559\nEpoch 110/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.8623\nEpoch 110: loss improved from 4.89431 to 4.87989, saving model to weights-improvement-110-4.8799-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.8624\nEpoch 111/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.8378\nEpoch 111: loss improved from 4.87989 to 4.87493, saving model to weights-improvement-111-4.8749-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.8380\nEpoch 112/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.8494\nEpoch 112: loss improved from 4.87493 to 4.86852, saving model to weights-improvement-112-4.8685-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.8495\nEpoch 113/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.8393\nEpoch 113: loss improved from 4.86852 to 4.86710, saving model to weights-improvement-113-4.8671-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.8395\nEpoch 114/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.8224\nEpoch 114: loss improved from 4.86710 to 4.85324, saving model to weights-improvement-114-4.8532-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.8226\nEpoch 115/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.8183\nEpoch 115: loss improved from 4.85324 to 4.84954, saving model to weights-improvement-115-4.8495-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.8185\nEpoch 116/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.7995\nEpoch 116: loss improved from 4.84954 to 4.84704, saving model to weights-improvement-116-4.8470-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.7998\nEpoch 117/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.7981\nEpoch 117: loss improved from 4.84704 to 4.83279, saving model to weights-improvement-117-4.8328-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.7983\nEpoch 118/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.8096\nEpoch 118: loss improved from 4.83279 to 4.82412, saving model to weights-improvement-118-4.8241-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.8097\nEpoch 119/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 4.8160\nEpoch 119: loss improved from 4.82412 to 4.82171, saving model to weights-improvement-119-4.8217-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.8161\nEpoch 120/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.7835\nEpoch 120: loss improved from 4.82171 to 4.80839, saving model to weights-improvement-120-4.8084-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.7836\nEpoch 121/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.7507\nEpoch 121: loss improved from 4.80839 to 4.80759, saving model to weights-improvement-121-4.8076-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.7510\nEpoch 122/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 4.7520\nEpoch 122: loss improved from 4.80759 to 4.79061, saving model to weights-improvement-122-4.7906-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 226ms/step - loss: 4.7522\nEpoch 123/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.7570\nEpoch 123: loss improved from 4.79061 to 4.78582, saving model to weights-improvement-123-4.7858-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.7572\nEpoch 124/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.7446\nEpoch 124: loss improved from 4.78582 to 4.78343, saving model to weights-improvement-124-4.7834-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.7448\nEpoch 125/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.7420\nEpoch 125: loss improved from 4.78343 to 4.77063, saving model to weights-improvement-125-4.7706-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.7421\nEpoch 126/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.7188\nEpoch 126: loss improved from 4.77063 to 4.75538, saving model to weights-improvement-126-4.7554-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.7190\nEpoch 127/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.7233\nEpoch 127: loss improved from 4.75538 to 4.75107, saving model to weights-improvement-127-4.7511-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.7234\nEpoch 128/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.7048\nEpoch 128: loss improved from 4.75107 to 4.74152, saving model to weights-improvement-128-4.7415-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.7050\nEpoch 129/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.7041\nEpoch 129: loss improved from 4.74152 to 4.73706, saving model to weights-improvement-129-4.7371-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.7042\nEpoch 130/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.6862\nEpoch 130: loss improved from 4.73706 to 4.72620, saving model to weights-improvement-130-4.7262-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.6864\nEpoch 131/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.6839\nEpoch 131: loss improved from 4.72620 to 4.71097, saving model to weights-improvement-131-4.7110-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.6841\nEpoch 132/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.6752\nEpoch 132: loss improved from 4.71097 to 4.70494, saving model to weights-improvement-132-4.7049-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.6753\nEpoch 133/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.6499\nEpoch 133: loss improved from 4.70494 to 4.68660, saving model to weights-improvement-133-4.6866-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.6501\nEpoch 134/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.6354\nEpoch 134: loss improved from 4.68660 to 4.68053, saving model to weights-improvement-134-4.6805-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.6356\nEpoch 135/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.6015\nEpoch 135: loss improved from 4.68053 to 4.66133, saving model to weights-improvement-135-4.6613-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.6018\nEpoch 136/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.6090\nEpoch 136: loss improved from 4.66133 to 4.65806, saving model to weights-improvement-136-4.6581-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.6092\nEpoch 137/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.5949\nEpoch 137: loss improved from 4.65806 to 4.64290, saving model to weights-improvement-137-4.6429-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.5952\nEpoch 138/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.5968\nEpoch 138: loss improved from 4.64290 to 4.63435, saving model to weights-improvement-138-4.6344-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.5970\nEpoch 139/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.5649\nEpoch 139: loss improved from 4.63435 to 4.61552, saving model to weights-improvement-139-4.6155-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.5652\nEpoch 140/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.5929\nEpoch 140: loss improved from 4.61552 to 4.61403, saving model to weights-improvement-140-4.6140-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.5930\nEpoch 141/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.5478\nEpoch 141: loss improved from 4.61403 to 4.58826, saving model to weights-improvement-141-4.5883-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.5480\nEpoch 142/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 4.5310\nEpoch 142: loss improved from 4.58826 to 4.57145, saving model to weights-improvement-142-4.5715-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 4.5312\nEpoch 143/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.5235\nEpoch 143: loss improved from 4.57145 to 4.56065, saving model to weights-improvement-143-4.5606-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.5237\nEpoch 144/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.4959\nEpoch 144: loss improved from 4.56065 to 4.54372, saving model to weights-improvement-144-4.5437-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.4961\nEpoch 145/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.4771\nEpoch 145: loss improved from 4.54372 to 4.52211, saving model to weights-improvement-145-4.5221-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.4773\nEpoch 146/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.4680\nEpoch 146: loss improved from 4.52211 to 4.51240, saving model to weights-improvement-146-4.5124-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.4682\nEpoch 147/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.4435\nEpoch 147: loss improved from 4.51240 to 4.49903, saving model to weights-improvement-147-4.4990-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.4438\nEpoch 148/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 4.4216\nEpoch 148: loss improved from 4.49903 to 4.46778, saving model to weights-improvement-148-4.4678-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 4.4219\nEpoch 149/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 4.3996\nEpoch 149: loss improved from 4.46778 to 4.45895, saving model to weights-improvement-149-4.4589-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 4.3999\nEpoch 150/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.3895\nEpoch 150: loss improved from 4.45895 to 4.43544, saving model to weights-improvement-150-4.4354-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.3897\nEpoch 151/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.3751\nEpoch 151: loss improved from 4.43544 to 4.41808, saving model to weights-improvement-151-4.4181-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.3753\nEpoch 152/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.3651\nEpoch 152: loss improved from 4.41808 to 4.41156, saving model to weights-improvement-152-4.4116-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.3653\nEpoch 153/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.3183\nEpoch 153: loss improved from 4.41156 to 4.37962, saving model to weights-improvement-153-4.3796-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.3186\nEpoch 154/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.3152\nEpoch 154: loss improved from 4.37962 to 4.36315, saving model to weights-improvement-154-4.3631-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.3155\nEpoch 155/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.2701\nEpoch 155: loss improved from 4.36315 to 4.33217, saving model to weights-improvement-155-4.3322-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.2705\nEpoch 156/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.2452\nEpoch 156: loss improved from 4.33217 to 4.31127, saving model to weights-improvement-156-4.3113-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.2455\nEpoch 157/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.2226\nEpoch 157: loss improved from 4.31127 to 4.29174, saving model to weights-improvement-157-4.2917-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.2230\nEpoch 158/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 4.2092\nEpoch 158: loss improved from 4.29174 to 4.26134, saving model to weights-improvement-158-4.2613-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 228ms/step - loss: 4.2095\nEpoch 159/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.1674\nEpoch 159: loss improved from 4.26134 to 4.22424, saving model to weights-improvement-159-4.2242-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.1677\nEpoch 160/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.1433\nEpoch 160: loss improved from 4.22424 to 4.20460, saving model to weights-improvement-160-4.2046-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 4.1436\nEpoch 161/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.1258\nEpoch 161: loss improved from 4.20460 to 4.19265, saving model to weights-improvement-161-4.1927-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.1262\nEpoch 162/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.0693\nEpoch 162: loss improved from 4.19265 to 4.15711, saving model to weights-improvement-162-4.1571-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.0698\nEpoch 163/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 4.0682\nEpoch 163: loss improved from 4.15711 to 4.13669, saving model to weights-improvement-163-4.1367-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 4.0685\nEpoch 164/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 4.0512\nEpoch 164: loss improved from 4.13669 to 4.11968, saving model to weights-improvement-164-4.1197-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 4.0516\nEpoch 165/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 4.0348\nEpoch 165: loss improved from 4.11968 to 4.08587, saving model to weights-improvement-165-4.0859-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 4.0351\nEpoch 166/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 3.9862\nEpoch 166: loss improved from 4.08587 to 4.05278, saving model to weights-improvement-166-4.0528-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 3.9865\nEpoch 167/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 3.9508\nEpoch 167: loss improved from 4.05278 to 4.01833, saving model to weights-improvement-167-4.0183-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 3.9511\nEpoch 168/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 3.9024\nEpoch 168: loss improved from 4.01833 to 3.97234, saving model to weights-improvement-168-3.9723-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 3.9028\nEpoch 169/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 3.8725\nEpoch 169: loss improved from 3.97234 to 3.96033, saving model to weights-improvement-169-3.9603-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 3.8730\nEpoch 170/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 3.8280\nEpoch 170: loss improved from 3.96033 to 3.92983, saving model to weights-improvement-170-3.9298-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 234ms/step - loss: 3.8286\nEpoch 171/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 3.8336\nEpoch 171: loss improved from 3.92983 to 3.89879, saving model to weights-improvement-171-3.8988-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 3.8340\nEpoch 172/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 3.7908\nEpoch 172: loss improved from 3.89879 to 3.86520, saving model to weights-improvement-172-3.8652-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 3.7912\nEpoch 173/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - loss: 3.7508\nEpoch 173: loss improved from 3.86520 to 3.83040, saving model to weights-improvement-173-3.8304-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 227ms/step - loss: 3.7512\nEpoch 174/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 3.7259\nEpoch 174: loss improved from 3.83040 to 3.79803, saving model to weights-improvement-174-3.7980-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 3.7262\nEpoch 175/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 3.6571\nEpoch 175: loss improved from 3.79803 to 3.76049, saving model to weights-improvement-175-3.7605-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 228ms/step - loss: 3.6576\nEpoch 176/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 3.6648\nEpoch 176: loss improved from 3.76049 to 3.72054, saving model to weights-improvement-176-3.7205-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 3.6651\nEpoch 177/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 3.6502\nEpoch 177: loss improved from 3.72054 to 3.70461, saving model to weights-improvement-177-3.7046-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 3.6504\nEpoch 178/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 3.5979\nEpoch 178: loss improved from 3.70461 to 3.65661, saving model to weights-improvement-178-3.6566-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 3.5983\nEpoch 179/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.5577\nEpoch 179: loss improved from 3.65661 to 3.63162, saving model to weights-improvement-179-3.6316-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.5581\nEpoch 180/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.5307\nEpoch 180: loss improved from 3.63162 to 3.59723, saving model to weights-improvement-180-3.5972-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.5310\nEpoch 181/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.4684\nEpoch 181: loss improved from 3.59723 to 3.55634, saving model to weights-improvement-181-3.5563-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.4688\nEpoch 182/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 3.4475\nEpoch 182: loss improved from 3.55634 to 3.52883, saving model to weights-improvement-182-3.5288-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 3.4479\nEpoch 183/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.3738\nEpoch 183: loss improved from 3.52883 to 3.47270, saving model to weights-improvement-183-3.4727-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.3743\nEpoch 184/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.3440\nEpoch 184: loss improved from 3.47270 to 3.43975, saving model to weights-improvement-184-3.4398-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.3445\nEpoch 185/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 3.3106\nEpoch 185: loss improved from 3.43975 to 3.40157, saving model to weights-improvement-185-3.4016-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 3.3111\nEpoch 186/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.3137\nEpoch 186: loss improved from 3.40157 to 3.39465, saving model to weights-improvement-186-3.3947-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.3142\nEpoch 187/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 3.2710\nEpoch 187: loss improved from 3.39465 to 3.35644, saving model to weights-improvement-187-3.3564-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 3.2715\nEpoch 188/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.2328\nEpoch 188: loss improved from 3.35644 to 3.31370, saving model to weights-improvement-188-3.3137-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.2333\nEpoch 189/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.1942\nEpoch 189: loss improved from 3.31370 to 3.27276, saving model to weights-improvement-189-3.2728-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.1946\nEpoch 190/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.1614\nEpoch 190: loss improved from 3.27276 to 3.23957, saving model to weights-improvement-190-3.2396-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.1619\nEpoch 191/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 3.0916\nEpoch 191: loss improved from 3.23957 to 3.17754, saving model to weights-improvement-191-3.1775-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 232ms/step - loss: 3.0920\nEpoch 192/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 3.0900\nEpoch 192: loss improved from 3.17754 to 3.16310, saving model to weights-improvement-192-3.1631-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 231ms/step - loss: 3.0904\nEpoch 193/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 3.0080\nEpoch 193: loss improved from 3.16310 to 3.11952, saving model to weights-improvement-193-3.1195-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 3.0086\nEpoch 194/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 3.0132\nEpoch 194: loss improved from 3.11952 to 3.09952, saving model to weights-improvement-194-3.0995-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 3.0137\nEpoch 195/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 2.9674\nEpoch 195: loss improved from 3.09952 to 3.05309, saving model to weights-improvement-195-3.0531-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 2.9679\nEpoch 196/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 2.9091\nEpoch 196: loss improved from 3.05309 to 3.01223, saving model to weights-improvement-196-3.0122-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 2.9097\nEpoch 197/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 2.8710\nEpoch 197: loss improved from 3.01223 to 2.97594, saving model to weights-improvement-197-2.9759-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 2.8716\nEpoch 198/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - loss: 2.8284\nEpoch 198: loss improved from 2.97594 to 2.94176, saving model to weights-improvement-198-2.9418-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 229ms/step - loss: 2.8290\nEpoch 199/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - loss: 2.8399\nEpoch 199: loss improved from 2.94176 to 2.93656, saving model to weights-improvement-199-2.9366-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 230ms/step - loss: 2.8404\nEpoch 200/200\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 2.7638\nEpoch 200: loss improved from 2.93656 to 2.87552, saving model to weights-improvement-200-2.8755-bigger.keras\n\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 231ms/step - loss: 2.7644\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pickle\nimport numpy\nfrom music21 import instrument, note, stream, chord\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Activation, BatchNormalization as BatchNorm\nfrom keras.utils import to_categorical\n\ndef generate():\n    \"\"\" Generate a piano midi file \"\"\"\n    #load the notes used to train the model\n    with open('data/notes', 'rb') as filepath:\n        notes = pickle.load(filepath)\n\n    # Get all pitch names\n    pitchnames = sorted(set(item for item in notes))\n    n_vocab = len(set(notes))\n\n    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n    model = create_network(normalized_input, n_vocab)\n    \n    # Use the most recent weights file\n    model.load_weights('weights-improvement-200-2.8755-bigger.keras')\n    \n    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n    create_midi(prediction_output)\n\ndef prepare_sequences(notes, pitchnames, n_vocab):\n    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n\n    sequence_length = 100\n    network_input = []\n    for i in range(0, len(notes) - sequence_length, 1):\n        sequence_in = notes[i:i + sequence_length]\n        network_input.append([note_to_int[char] for char in sequence_in])\n\n    n_patterns = len(network_input)\n    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n    normalized_input = normalized_input / float(n_vocab)\n\n    return (network_input, normalized_input)\n\ndef create_network(network_input, n_vocab):\n    \"\"\" create the structure of the neural network \"\"\"\n    model = Sequential()\n    model.add(LSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True))\n    model.add(Dropout(0.3))\n    model.add(LSTM(512, return_sequences=True))\n    model.add(Dropout(0.3))\n    model.add(LSTM(512))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNorm())\n    model.add(Dropout(0.3))\n    model.add(Dense(n_vocab))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n\n    return model\n\ndef generate_notes(model, network_input, pitchnames, n_vocab):\n    \"\"\" Generate notes from the neural network \"\"\"\n    # Pick a random sequence from the input as a starting point\n    start = numpy.random.randint(0, len(network_input)-1)\n    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n\n    pattern = network_input[start]\n    prediction_output = []\n\n    # Generate 500 notes\n    for note_index in range(500):\n        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1))\n        prediction_input = prediction_input / float(n_vocab)\n\n        prediction = model.predict(prediction_input, verbose=0)\n        index = numpy.argmax(prediction)\n        result = int_to_note[index]\n        prediction_output.append(result)\n        \n        pattern.append(index)\n        pattern = pattern[1:len(pattern)]\n\n    return prediction_output\n\ndef create_midi(prediction_output):\n    \"\"\" convert the output from the prediction to notes and create a midi file \"\"\"\n    offset = 0\n    output_notes = []\n\n    # Create note and chord objects\n    for pattern in prediction_output:\n        # Pattern is a chord\n        if ('.' in pattern) or pattern.isdigit():\n            notes_in_chord = pattern.split('.')\n            notes = []\n            for current_note in notes_in_chord:\n                new_note = note.Note(int(current_note))\n                new_note.storedInstrument = instrument.Piano()\n                notes.append(new_note)\n            new_chord = chord.Chord(notes)\n            new_chord.offset = offset\n            output_notes.append(new_chord)\n        # Pattern is a note\n        else:\n            new_note = note.Note(pattern)\n            new_note.offset = offset\n            new_note.storedInstrument = instrument.Piano()\n            output_notes.append(new_note)\n\n        offset += 0.5\n\n    midi_stream = stream.Stream(output_notes)\n    midi_stream.write('midi', fp='output_1.mid')\n\nif __name__ == '__main__':\n    generate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T03:34:10.287385Z","iopub.execute_input":"2024-12-01T03:34:10.287738Z","iopub.status.idle":"2024-12-01T03:34:42.963805Z","shell.execute_reply.started":"2024-12-01T03:34:10.287708Z","shell.execute_reply":"2024-12-01T03:34:42.963062Z"}},"outputs":[],"execution_count":9}]}